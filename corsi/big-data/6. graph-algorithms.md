Introduzione ai grafi nel contesto di MapReduce ed approfondimento di due algoritmi coi grafi interessanti:
- Parallel Breadth-First Search
- Page Rank
Infine, piccola panoramica su sistemi moderni come Pregel.

---
# Grafi e MapReduce
Una grande quantità di problemi sono risolvibili attraverso l'uso di grafi, ogni algoritmo del genere comprende:
- computazioni su ogni nodo, basate sulle caratteristiche del nodo stesso, dell'arco o della struttura del grafo
- la propagazione della computazione attraversando il grafo steso

## Rappresentazione del grafo
La rappresentazione del grafo (utile anche negli algoritmi basati su MapReduce) può essere messa in pratica tramite:
- **Matrici di adiacenza**
- **Liste di adiacenza**

![[graph-algorithms-image-1 | 100%]]
### Matrici di adiacenza
Il grafo viene rappresentato tramite una matrice $n \cdot n$, dove $n$ è il numero di nodi $|V|$.
Vantaggi:
- adatta a manipolazioni matematiche
- le iterazioni su righe e colonne corrispondono a computazioni su link in entrata e link in uscita
Svantaggi:
- tanto spazio sprecato
### Liste di adiacenza
Rappresentazione tramite liste in cui tutti gli zeri delle matrici di adiacenza sono eliminati.
Vantaggi:
- rappresentazione più compatta
- facile da computare sui link in uscita
Svantaggi:
- più difficile da computare sui link in **entrata**



---
# Parallel Breadth-First Search

> [!warning] Problema - Single-Source Shortest Path (SSSP)
> Trovare il percorso più corto dalla sorgente rispetto a tutti i nodi del grafo.

Sulla singola macchina tale problema è risolto grazie al famosissimo algoritmo di Dijkstra.

![Dijkstra_Animation.gif (283×222) | 500](https://upload.wikimedia.org/wikipedia/commons/5/57/Dijkstra_Animation.gif)

La **Parallel Breadth-First Search (BFS)** con **MapReduce** è una strategia fondamentale per trovare il **Single-Source Shortest Path (SSSP)** in grandi grafi distribuiti.

## Obiettivo
Obiettivi della Parallel BFS:
- trovare il cammino più breve da un nodo sorgente a tutti gli altri nodi di un grafo **distribuito** (il fine non cambia).
- utilizzare l'approccio di **flooding iterativo**, simile a una BFS classica, ma adattata a un ambiente distribuito come MapReduce.

Il **flooding iterativo** è una tecnica che imita il comportamento di un’onda che si espande progressivamente nel grafo, livello dopo livello, **a partire da un nodo sorgente**:
- ogni iterazione esplora i nodi vicini a quelli scoperti nella fase precedente
- in ogni ciclo, si scoprono i nodi a distanza crescente
- l'esecuzione si ripete finché non ci sono più nodi da scoprire

## MapReduce Implementation
Ogni nodo è rappresentato attraverso la seguente tupla:
$$\texttt{(node\_id, adjacency\_list, distance)}$$
e il grafo viene mantenuto in memoria attraverso una lista di adiacenza.

Esecuzione di una singola iterazione:
1. **Mapper**
	- per ogni nodo $n$ attivo (non ancora scoperto, quindi con distanza definita $\neq \infty$), viene emessa:
		- la propria struttura dati `emit (node_id, adjacency_list, distance)`
		- una coppia `emit (neighbor_id, adjacency_list, distanza_attuale + 1)`
2. **Shuffle & Sort**
	- raggruppa tutte le informazioni ricevute dai mapper per ciascun nodo
3. **Reducer**
	- per ogni tupla avente nodo $n$ 
		- confronta le distanze ricevute e seleziona la minima
		- aggiorna la distanza se quella nuova è la più breve
		- emette la nuova struttura del nodo aggiornata

Ogni Job MapReduce corrisponde a un livello della BFS: ogni iterazione espande la frontiera di ricerca di un livello di nodi.
Quindi si itera finché ogni nodo non è scoperto, ovvero possiede una distanza $\neq \infty$.

Per identificare la terminazione dell'algoritmo (ogni nodo è stato scoperto) si utilizza un programma "driver" che permette la verifica, tale programma è necessario finché si uso di un paradigma iterativo.

Vantaggi:
- **adatto a grafi small-world**, ovvero di piccolo diametro e poche iterazioni
- si può **estendere facilmente** a grafi ponderati (ogni arco ha un peso) oppure ricavare direttamente il percorso più breve
Svantaggi:
- **il passaggio del grafo intero dal mapper al reducer** potrebbe essere un'operazione davvero costosa e direttamente proporzionale alla grandezza del grafo stesso


---
# Page Rank
PageRank è un algoritmo nato per classificare la rilevanza di una specifica pagina web.

PageRank assegna a ciascun nodo di un grafo un **valore di importanza**, basato su una simulazione semplificata del comportamento di un navigatore casuale.
In questo modo viene misurato quanto spesso questo navigatore casuale si trova su una certa pagina, più tale valore sarà alto maggiore sarà l'importanza della pagina stessa.

## Formula matematica
Si $G$ un grafo che rappresenta le con ogni suo nodo $n$ una pagina, allora il valore di rilevanza si ottiene utilizzando la seguente formula ricorsiva:
$$P(n) = \frac{\alpha}{|G|} + (1 - \alpha) \sum_{m\in L(n)}{\frac{P(m)}{C(m)}}$$
- $P(n)$ - valore di rilevanza per un nodo $n$
- $\alpha$ - fattore di teletrasporto (random jump factor, di solito 0.15)
- $L(m)$ - insieme dei nodi che puntano a $n$
- $P(m)$ - valore di rilevanza della pagina $m$, ovvero una delle pagine raggiungibili da $n$
- $C(m)$ - numero di link in uscita da $m$

Dalla formula si evince facilmente che all'aumentare del numero di link complessivi che puntano ad una pagina "A", allora il PageRank della pagina stessa aumenta.

## Calcolo iterativo
Per usufruire della formula iterativamente è necessario:
1. inizializzare i valori PageRank di ogni nodo $n$ ad un valore standard, in questo caso $\forall n \in G \rightarrow P(n) = \frac{1}{|G|}$
2. ad ogni iterazione aggiornare il valore $P(n)$ usando la formula soprariportata, finché i valori non convergono
3. ottenuta la convergenza e verificata (tramite un driver apposito) terminare l'esecuzione

La convergenza può essere raggiunta quando i PageRank variano per un valore minore di una certa soglia.

## MapReduce Implementation
Nel contesto MapReduce:
- **Mapper**
	- emette la propria struttura per non rovinare il grafo 
	- per ogni nodo $n$, calcola $p$ come $p = \frac{P(n)}{C(n)}$
	- condivide ad ogni vicino il valore $p$ appena calcolato
- **Reducer**
	- raccoglie tutte le quote $p$ da ogni nodo
	- somma e aggiorna il nuovo valore di PageRank usando anche il fattore casuale $\alpha$
	- restituisce la struttura aggiornata per l'iterazione successiva

Vantaggi:
- funziona bene su grandi grafi distribuiti
- modello intuitivo di navigazione
Svantaggi:
- i nodi senza uscite perdono massa PageRank, serve un job extra per ridistribuirla

---
# Pregel
