Breve introduzione ai topic del corso con relative definizioni preliminari:
- big data, computazione parallela e sistemi distribuiti
- big data e machine learning
- cloud computing

---

# Big Data

> [!info] Big Data
> Dati la cui scala, diversità e complessità richiedono nuove architetture, tecniche, algoritmi e analisi per gestirli ed estrarre valore e conoscenza nascosta.

Caratteristiche principali:
- **Volume** - scala (mole) dei dati
- **Variety** - differenze nella tipologia di dati
- **Velocity** - analisi di dati streaming
- *Veracity* - incertezza sui dati
- *Value* - valore dato dall'analisi dei dati

## Parallel Computing
Lo strumento utile all'analisi di grandi datasets sono i **cluster di elaboratori**.

Alcuni **principi fondamentali** per progettare sistemi in grado di gestire efficacemente i Big Data in un contesto di calcolo parallelo e distribuito:
- **scalare orizzontalmente** (i.e. aumentare il n° di elaboratori) piuttosto che scalare verticalmente (i.e. potenziare le macchine esistenti)
- assumere eventuali **guasti/fallimenti come avvenimenti comuni**, che possono accadere
- spostare l'elaborazione ai dati, ovvero è una pratica migliore **spostare il calcolo dove si trovano i dati** piuttosto che spostare grandi quantità di dati verso il calcolo
- elaborare i dati in maniera sequenziale, **è più efficiente leggere ed elaborare i dati in modo sequenziale** piuttosto che fare accessi casuali
- gli sviluppatori di applicazioni non dovrebbero preoccuparsi di dettagli come distribuzione, gestione errori o concorrenza

Quindi un sistema di computazione parallela deve garantire:
- distribuzione dei dati
- computazione distribuita
- tolleranza ai guasti
- schedulazione delle task

Il framework che orchestra il sistema deve nascondere i dettagli di basso livello, separando il ***cosa*** dal ***come***.

Quali sono i problemi adatti al parallel computing?
- **Embarrassingly parallel problems** - sono problemi in cui diverse parti del dataset possono essere processate in maniera *totalmente indipendente*
	- non è scontato capire se un problema può essere suddiviso in sotto problemi indipendenti
- **Batch processing of large datasets** - carichi di lavoro che richiedono l'elaborazione dell'intero dataset, in modalità batch (i.e. non interattiva o in tempo reale)
	- comportano **scansioni complete** di grandi datasets
	- tanti dati quindi **uso intenso di I/O** e parallelismo
	- spesso i datasets sono talmente grandi da non poter essere caricati in memoria completamente e quindi devono essere **elaborati in streaming**

## Big Data and Machine Learning
Gli strumenti di analisi di big data permettono la gestione e trasformazione dei dati in una forma utilizzabile per i sistemi di machine learning.

I sistemi di analisi e trasformazione dati sono **fondamentali** per la creazione di buoni sistemi di machine learning!

## Cloud Computing
Servizi informatici forniti tramite Internet piuttosto che localmente sulla macchina di un utente, essi devono garantire:
- uso on-demand
- distribuzione delle risorse
- elasticità
- misurazione del servizio