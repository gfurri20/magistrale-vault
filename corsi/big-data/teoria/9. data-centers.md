Panoramica completa sull'evoluzione dei data center moderni: architettura fisica, rete, SDN, gestione delle risorse tramite Cloud OS.
Inoltre vengono approfonditi strumenti, problematiche e tecnologie emergenti.


---

# Rack, Cluster e Data Center
Con l'aumentare delle richieste di calcolo quotidiane la singola macchina risulta essere insufficiente.

***Rack***
**Insieme fisico di server fisici, simili tra loro, interconnessi** sulla rete tramite un *ToR - Top of the Rack switch*.

***Cluster***
**Insieme logico di server fisici** (può essere composto da uno o più rack) che lavorano assieme con l'obiettivo di migliorare le prestazioni e l'affidabilità di un processo di calcolo.

***Data Center***
Un edificio dedicato che **raggruppa svariati cluster tra di loro**, dotato delle tecnologie necessarie per gestire ogni bisogno dell'infrastruttura.

Per gestire le enormi richieste di calcolo, tali data center possono essere interconnessi tra loro tramite rete.

## Energia e raffreddamento
I data centers sono caratterizzati da un **elevato consumo energetico** (ogni rack può consumare >4.5 kW).

La maggior parte dell’energia diventa calore, di conseguenza **il raffreddamento è fondamentale**.

---

# Topologie di rete nei Data Center

Layer 2 (Data Link Layer):
- Utilizza **Ethernet switching**.
- Un **albero di spanning** viene costruito per prevenire i loop → blocca percorsi alternativi.    
- **Problema**: non sfrutta al meglio tutte le risorse di rete disponibili.
Layer 3 (Network Layer):
- Usa **routing IP** con instradamento a cammino minimo.
- Non garantisce delivery, è **best-effort**.
- Sfrutta tutti i link disponibili, ma ha **latenze e costi di configurazione più alti**.

## Architettura tradizionale
Una tipica architettura di data center è **gerarchica**:
1. Core Router - livello 3 di rete
2. Aggregation Layer - livello 2 di rete
3. Access Layer - livello dei racks

Pro:
- Compatibilità con applicazioni esistenti (Ethernet-based).
- Infrastruttura semplice ed economica.
- Basso consumo energetico.

Contro:
- **Single point of failure** in alto nella gerarchia.
- **Over-subscription**: i link superiori sono spesso condivisi tra molti server → colli di bottiglia.
- Non ottimale per il traffico est-ovest (server-server).

## Architettura Fat-Tree
Risulta essere un’architettura **scalabile** e **bilanciata** per supportare grandi quantità di traffico server-to-server, usando **dispositivi economici**.

Struttura:
- Basata su **switch a k-port**.
- l’architettura può supportare fino a **(k³/4) host**.

Vantaggi:
- Ogni switch può trasmettere a velocità di linea (line rate).
- Architettura altamente **scalabile e fault-tolerant**.
- Adatta a grandi data center.

### ECMP (Equal-Cost Multi-Path Routing)
Per sfruttare i molteplici percorsi nel Fat-tree, si usa **ECMP**:
- I flussi vengono bilanciati usando un **hash** delle intestazioni dei pacchetti (indirizzo sorgente/destinazione).
- Ogni flusso è mappato su un **singolo cammino** → preserva l’ordine dei pacchetti.

Limiti:
- Non tutti i flussi sono uguali:
    - **Mice flows** (brevi, piccoli)
    - **Elephant flows** (lunghi, pesanti).
- ECMP può causare **squilibri** se troppi elephant flows sono hashati sullo stesso percorso.
- Mancanza di supporto nativo a **VLAN**.
- Difficoltà di espandere dinamicamente l’architettura (aggiunta rack difficile).

## Architetture ibride
Non tutto il traffico è distribuito uniformemente: la maggior parte del traffico è **intra-rack**; solo pochi flussi sono **lunghi e inter-rack**.

Di conseguenza si potrebbe dividere la rete in base alla tecnologia di trasferimento fisico:
- Rete **elettrica a pacchetti** per traffico generico e reattivo.
- Rete **ottica a circuiti** per flussi lunghi → percorso dedicato e ad alta capacità.

Un **controller centralizzato** stima la domanda di traffico e configura dinamicamente i circuiti ottici (es. con algoritmo di _maximum weighted matching_).
I pacchetti sono raggruppati per flusso (batching) per migliorare l’efficienza dell’ottico.


---

# Software Defined Networking (SDN)
Le apparecchiature su cui si basa Internet sono "chiuse" e difficili da innovare, il controllo distribuito è complesso da applicare e spesso si verificano errori di vario genere.

Poche aziende hanno la possibilità di innovare e questo introduce lunghe attese rispetto alle nuove ed innovative feature.

Questo comporta una **difficoltà a migliorare performance, sicurezza, affidabilità e costi**.
La rete diventa un **ostacolo** anziché un facilitatore, soprattutto nei data center.

Il **Software Defined Networking** rappresenta una **rottura radicale** con il modello di rete tradizionale. Nei data center moderni, dove l’agilità, il controllo e l’automazione sono essenziali, SDN consente di:
- Gestire dinamicamente la rete,
- Programmare logiche avanzate (security, bilanciamento, failover),
- Ridurre costi e semplificare il troubleshooting.

## Separazione del lavoro

### Reti tradizionali
Divisione del lavoro nelle reti tradizionali:
- **Data plane**: elabora pacchetti (forwarding, filtraggio).
- **Control plane**: decide i percorsi (routing, regole).
- **Management plane**: configurazione e gestione (manuale o automatizzata).

Problema: sono **tutti distribuiti** e difficili da gestire.

### Death to the Control Plane
SDN propone di **centralizzare logicamente il piano di controllo**, separandolo dall'hardware, creando di fatto un livello lento ed intelligente ed uno veloce ma stupido.

Vantaggi della centralizzazione:
- Gestione semplificata.
- Innovazione rapida e indipendente dai vendor.
- Apparati di rete diventano **semplici, veloci e generici**.
- Maggiore **interoperabilità**: solo i protocolli sul filo devono essere compatibili.

## Architettura SDN
Componenti principali:
- **Controller (Network OS)** - cervello della rete
	- più lento ma più intelligente
- **Switch** - eseguono le istruzioni impartite dal controller
- **API** - per la comunicazione tra Controller e Switches (e.g. OpenFlow)


---

# Cloud OS
**I data center**, al giorno d'oggi, **hanno bisogno di un sistema operativo proprio**, utile per:
- processare dati tramite un framework designato
- gestire gli storage systems e risorse
- gestire utenti ed applicazioni

L'obiettivo futuro è quello di costruire un sistema operativo per data centers in grado di:
- condividere risorse in maniera efficiente fra tutti i nodi
- condividere dati, attraverso un sistema unificato per la gestione della memoria
- gestione delle astrazioni di programmazione
	- strumenti che facilitino l'uso dei vari framework
	- implementazione efficace delle primitive di comunicazione
	- creazione di nuovi modelli di programmazione distribuiti
- miglioramento delle possibilità di debugging
	- strumenti di debugging che lavorano intra-rack
	- modello unificato per il monitoraggio delle API e dell'infrastruttura

## Architettura
La **virtualizzazione** è la chiave per aumentare l'efficienza dei data center.

![1.jpeg (796×768)](https://3hcloud.com/upload/iblock/1a3/mzqalim796g8jr5u5fk4aevmqlbxsz04/1.jpeg)

Il cloud operating system è anche chiamato **Virtual Infrastructure Manager** e svolge i seguenti compiti fondamentali:
- orchestra le risorse virtuali
- gestisce le interfacce fisiche in relazione a quelle virtuali

Esso fa riferimento ad altri componenti:
- **Virtual Machine Manager** - gestisce il ciclo di vita delle VM e fornisce isolamento tra utenti
	- le VM sono l'unità base d'esecuzione, ognuna ha le proprie caratteristiche ed attributi
- **Network Manager** - crea reti virtuali private e pubblica ed isola il traffico tra suddette reti
- **Storage Manager** - fornisce spazio storage virtuale, scalabile e affidabile
- **Image Manager** - gestisce le immagini di creazione delle VM, utili per clonazione e condivisione
	- ogni immagine può essere impostata per svariati scopi e personalizzata con i tools necessari
- **Information Manager** - raccoglie dati sullo stato delle VM, dell'hardware sul quale esse girano e sull'infrastruttura di rete stessa

Inoltre, un sistema operativo cloud può fare affidamento a diversi servizi:
- **Authentication e Authorization**
	- autenticazione di utenti ed amministratori
	- gestione dei permessi e delle autorizzazioni, tramite **access control**
- **Accounting**
	- **informazioni d'uso** dei servizi deployati
	- monitoraggio delle azioni compiuti rispetto all'utente
	- fondamentale per produrre le **quote di pagamento**
- **Auditing**
	- raccoglie i file di log sulle risorse dell'infrastruttura
	- utile per studiare ed in caso aumentare la sicurezza del sistema
- **Scheduler** - decide dove installare ogni VM in base a criteri specifici, ci sono due scheduler:
	- **livello cloud**, decide su quale specifico server fisico installare ogni VM
	- **livello fisico**, decide quando le VM possono ottenere le risorse necessarie, ma anche quali
- **Tool Amministrativi** - interfacce per utenti e amministratori utili alla gestione delle risorse
	- admin del data center per la gestione totale
	- utenti cloud per la gestione della loro porzione (nelle modalità pattuite)






