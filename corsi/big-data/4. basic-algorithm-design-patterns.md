Panoramica sui vari design pattern: vantaggi, svantaggi e le loro applicazioni:
- Pairs approach
- Stripes approach

---

# MapReduce Algorithm Design
Sviluppare un algoritmo basato su MapReduce significa:
- preparare i dati in input, la struttura dati svolge un ruolo fondamentale
- implementare i mapper e i reducer, alcune volte c'è da "piegare" a favore il framework
- che non sempre è facile esprimere la logica dell'algoritmo

Inoltre, diversi ci sono diversi **aspetti che non possono essere controllati** dall'analista:
- dove e quando i mapper e i reducer agiranno
- quali coppie chiave-valore saranno processate da uno specifico mapper
- quali coppie chiave-valore intermedie saranno processate da uno specifico reducer
Al contrario, **ciò che un analista può controllare**:
- la **struttura dati** chiave-valore
- l'ordine di sort delle chiavi intermedie, quindi l'ordine con il quale il reducer incontrerà le chiavi
- il partizionamento dello spazio delle chiavi, quindi l'insieme delle chiavi che verranno processate da un particolare reducer

Adattare un algoritmo a MapReduce può essere un lavoro complicato:
- molti algoritmi non possono essere facilmente espressi in un singolo Job
- algoritmi iterativi richiedono un driver esterno


## Pairs and Stripes
Il design pattern **Pairs and Stripes** è una strategia utile per implementare algoritmi di co-occorrenza (come nel calcolo di matrici di co-occorrenza di parole) usando il framework MapReduce. Entrambi i metodi mirano a portare insieme i dati pertinenti nel momento giusto e nel posto giusto del processo distribuito, ma **differiscono per struttura e prestazioni**.

**Quando scegliere uno o l’altro?**
- **Pairs** va bene quando hai limiti di memoria o dataset altamente distribuiti.
- **Stripes** è più efficiente per dataset che permettono il buffering in memoria e se i combiners sono utili.

> [!warning] Problema
> Costruzione di un contatore di co-occorrenza di parole in un determinato contesto (può essere una frase, un paragrafo oppure un documento):
> - matrice n x n, dove n è il numero di parole del dizionario
> - ogni cella $m_{ij}$ contiene il numero di volte in cui le due parole sono co-occorrenti

Analizzare un problema del genere permette di stimare la distribuzione di eventi congiunti discreti da un gran numero di osservazioni.

Alcune osservazioni:
- la complessità spaziale sarà di $O(n^2)$, dove $n$ è la grandezza del vocabolario
- se la matrice può stare in memoria di un singolo elaboratore, allora non serve un algoritmo distribuito

### Pairs Approach
Il **Mapper** emette coppie di parole co-occorrenti come chiavi, con valore `1` per indicare un'apparizione, esegue ciò attraverso due cicli annidati attraversano ciascun documento; per ogni parola viene emessa una coppia $(w_i, w_j)$.
Il **Reducer** aggrega tutti i conteggi per ogni coppia, restituendo la frequenza assoluta di co-occorrenza.

Vantaggi:
- più semplice da implementare
- non richiede strutture complesse in memoria

Svantaggi:
- genera un numero considerevole di dati intermedi

### Stripes Approach
Il **Mapper** costruisce una **mappa associativa** (tipo dizionario) che, per ogni parola $w_i$, associa le parole co-occorrenti $w_j$ con la loro frequenza. Tali mappe sono accumulate in memoria per poi essere emesse.
Il **Reducer** unisce le varie mappe associative ricevute per la stessa parola $w_i$ con una somma elemento per elemento.

Vantaggi:
- più compatto
- meno chiavi da ordinare
- valori più ricchi ed espressivi

Svantaggi:
- rischio di superare la memoria disponibile se le mappe diventano troppo grandi


## Relative Frequencies
Il problema principale con i **conteggi assoluti** è che alcune parole appaiono molto frequentemente (come articoli o preposizioni), e ciò può distorcere l’analisi. Le **frequenze relative** aiutano a normalizzare questo effetto.

La frequenza relativa tra due parole $w_i$ e $w_j$ si calcola così:

$$f(w_j∣w_i) = \frac{N(w_i, w_j)}{\sum_{w'} N(w_i, w')}$$

Dove:
- $N(w_i, w_j)$ è il numero di volte che $w_j$ appare nel contesto di $w_i$
- Il denominatore è la **marginale**, ossia la somma di tutte le co-occorrenze di $w_i$

### Stripe Implementation
Ogni **Mapper** costruisce una mappa associativa con i vicini di $w_i$
Il **Reducer** somma le mappe e calcola la marginale, infine divide ogni frequenza congiunta per la marginale, ottenendo così le frequenze relative $f(w_j∣w_i)$

Il vantaggio qui è che, usando le strutture in memoria (le stripe), si ha accesso simultaneo a tutte le co-occorrenze di $w_i$, permettendo una normalizzazione efficiente.


## Inverted Indexing
L’**inverted indexing** è un concetto chiave nei sistemi di recupero dell’informazione, come i motori di ricerca, ed è un ottimo esempio di algoritmo “big data” implementabile in MapReduce.

Un **indice invertito** associa a ogni parola (termine) l’elenco dei documenti in cui essa appare. È l’opposto di un indice "normale", che elenca i termini contenuti in un documento.

```
"termine" → [doc1, doc2, doc4]
```

**Mapper**
- Legge ogni documento.
- Per ogni parola, emette una coppia chiave-valore:
    - **Chiave**: il termine.
    - **Valore**: l’ID del documento in cui si trova, e in caso anche il numero di apparizioni

**Reducer**
- Riceve tutti i documenti associati a un termine.
- Costruisce una lista (o "posting list") contenente:
    - Gli ID dei documenti.
    - Eventualmente il numero di occorrenze del termine in ogni documento.

Alla fine, si ottiene un indice compatto e consultabile velocemente per ogni termine.