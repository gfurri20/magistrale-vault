{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b35cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# for temporal evaluation\n",
    "from functools import wraps\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692546ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging setup\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6a00c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    def __init__(self, id, text, answers_domain, answer_index):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.answers_domain = answers_domain\n",
    "        self.answer_index = answer_index\n",
    "        \n",
    "    def is_correct(self, response):\n",
    "        \"\"\"Checks if the response matches the correct answer.\"\"\"\n",
    "        return response.strip().lower() == self.answers_domain[self.answer_index].strip().lower()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.id}: {self.text} between the following options: {self.answers_domain}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71872764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogErrorCode():\n",
    "    MODEL_ERROR = 101\n",
    "    JSON_PARSE_ERROR = 201\n",
    "    MISSING_SHORT_ANSWER = 301\n",
    "    \n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        if code == self.MODEL_ERROR:\n",
    "            self.message = \"Model returned an error.\"\n",
    "        elif code == self.JSON_PARSE_ERROR:\n",
    "            self.message = \"Error parsing JSON response.\"\n",
    "        elif code == self.MISSING_SHORT_ANSWER:\n",
    "            self.message = \"Missing short answer in response.\"\n",
    "        else:\n",
    "            self.message = \"Unknown error code.\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[Error {self.code}]: {self.message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cabf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OpenAI client\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"DENIS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3a70b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication: reduced size from 30059 to 10279.\n",
      "Remove one every 2: reduced size from 10279 to 5140.\n",
      "Remove one every 2: reduced size from 5140 to 2570.\n",
      "Remove one every 2: reduced size from 2570 to 1285.\n"
     ]
    }
   ],
   "source": [
    "# dataset reduction procedures\n",
    "def duplicate_lines_remover(csv_listed_dataset):\n",
    "    \"\"\"\n",
    "    Remove duplicate subsequent equal lines from the CSV data.\n",
    "    \"\"\"\n",
    "    csv_text_clean = [csv_listed_dataset[0]]\n",
    "    starting_len = len(csv_listed_dataset[1:])\n",
    "    for line in csv_listed_dataset[1:]:\n",
    "        if csv_text_clean[-1] != line:\n",
    "            csv_text_clean.append(line)\n",
    "    print(\n",
    "        f\"Deduplication: reduced size from {starting_len} to {len(csv_text_clean) - 1}.\")\n",
    "    return csv_text_clean\n",
    "\n",
    "\n",
    "def reduce_size(csv_listed_dataset, remove_one_every_n=2, times=1):\n",
    "    \"\"\"\n",
    "    Reduce the size of the dataset by removing one row every n rows.\n",
    "    \"\"\"\n",
    "    clean_data = [csv_listed_dataset[0]]\n",
    "    starting_len = len(csv_listed_dataset[1:])\n",
    "    for i in range(1, starting_len + 1):\n",
    "        if i % remove_one_every_n == 0:\n",
    "            continue\n",
    "        clean_data.append(csv_listed_dataset[i])\n",
    "    print(f\"Remove one every {remove_one_every_n}: reduced size from {starting_len} to {len(clean_data) - 1}.\")\n",
    "    return clean_data\n",
    "\n",
    "\n",
    "def header_anonymizer(csv_listed_dataset):\n",
    "    \"\"\"\n",
    "    Anonymize the header of the CSV data, substituing register names with letters.\n",
    "    \"\"\"\n",
    "    # Header anonymization\n",
    "    old_header = csv_listed_dataset[0].split(\",\")\n",
    "    new_header = \",\".join([chr(ord('A') + i) for i in range(len(old_header))])\n",
    "    anonymized_header_csv_listed_dataset = [c for c in csv_listed_dataset]\n",
    "    anonymized_header_csv_listed_dataset[0] = new_header\n",
    "\n",
    "    # reference mapping (letter, original register name)\n",
    "    ref = {chr(ord('A') + i): old_header[i] for i in range(len(old_header))}\n",
    "    \n",
    "    return (anonymized_header_csv_listed_dataset, ref)\n",
    "\n",
    "\n",
    "# dataset selection\n",
    "#TESTED_DATASET = \"plc_data_log_20251128_212142\"\n",
    "TESTED_DATASET = \"baseline\"\n",
    "\n",
    "# dataset reading\n",
    "with open(f\"../datasets/swat/{TESTED_DATASET}.csv\", \"r\") as f:\n",
    "    csv_text = f.read()\n",
    "    \n",
    "# csv file in which every line is an element of a list (header included)\n",
    "csv_listed_dataset = csv_text.split(\"\\n\")\n",
    "\n",
    "# deduplication\n",
    "to_analyze = duplicate_lines_remover(csv_listed_dataset)\n",
    "# size reduction\n",
    "to_analyze = reduce_size(to_analyze)\n",
    "to_analyze = reduce_size(to_analyze)\n",
    "to_analyze = reduce_size(to_analyze)\n",
    "\n",
    "# header anonymization\n",
    "anonymized_to_analyze, reference_mapping = header_anonymizer(to_analyze)\n",
    "\n",
    "# final dataset size and name\n",
    "compressed_dataset_size = len(to_analyze) - 1\n",
    "tested_dataset_name = f\"{TESTED_DATASET}_compressed_{compressed_dataset_size}_rows.csv\"\n",
    "\n",
    "text_data = \"\\n\".join(to_analyze)\n",
    "anonymized_text_data = \"\\n\".join(anonymized_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404bc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1_1 = Question(\n",
    "    id=\"Q1.1\",\n",
    "    text=\"Infer, based on data provided, what type of physical Industrial Control System (ICS)\",\n",
    "    answers_domain=[\n",
    "        'Energy & Power System',\n",
    "        'Oil, Gas & Chemicals System',\n",
    "        'Manufacturing System',\n",
    "        'Water & Wastewater System',\n",
    "        'Building Automation System',\n",
    "        'Not Identifiable'\n",
    "    ],\n",
    "    answer_index=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc4b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.1 Possible ICS Type Identification\n",
    "domain = [\n",
    "    \"Power Generation Plant\",\n",
    "    \"Manufacturing Assembly Line\",\n",
    "    \"Oil and Gas Refinery\",\n",
    "    \"Water Purification Plant\",\n",
    "    \"Nuclear Power Plant\",\n",
    "    \"Not Identifiable\"\n",
    "]\n",
    "correct_answer_index = 3 # Water Purification Plant\n",
    "\n",
    "question = f\"Q1.1: Infer, based on data provided, what type of phisical Industrial Control System (ICS) between the following options: {domain}\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb43eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1 Tanks Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q2.1: Only based on data provided, identify how many tanks are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83d7bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1 PLCs Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q3.1: Based on provided data and context, identify how many PLCs are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes. The operations involve three water tanks having varying capacities.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8274ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prompt(model_name, prompt, data):\n",
    "    try:\n",
    "        c = CLIENT.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": data}]\n",
    "                },\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"response\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"response\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"short_answer\": {\n",
    "                                        \"enum\": domain\n",
    "                                    },\n",
    "                                    \"confidence\": {\n",
    "                                        \"type\": \"number\",\n",
    "                                        \"description\": \"Confidence level from 0 to 1, where 1 is highest\"\n",
    "                                    },\n",
    "                                    \"reasoning\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Reasoning behind the answer\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"short_answer\", \"confidence\", \"reasoning\"]\n",
    "                            },\n",
    "                            \"limitations\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"List of limitations or uncertainties in the analysis\"\n",
    "                            },\n",
    "                            \"internal_checks\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"columns_used\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of columns from the dataset that were used in the analysis\"\n",
    "                                    },\n",
    "                                    \"assumptions_detected\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of assumptions made during the analysis\"\n",
    "                                    },\n",
    "                                    \"warnings\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of warnings or potential issues identified during the analysis\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"columns_used\", \"assumptions_detected\", \"warnings\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"response\", \"limitations\", \"internal_checks\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw = c.choices[0].message.content\n",
    "        if not raw:\n",
    "            raise Exception(\"No content in response\")\n",
    "        return raw\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3697e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, prompt, csv_data, repetitions=10):\n",
    "    '''\n",
    "    Evalute accuracy of multiple models on the given prompt and data.\n",
    "    '''\n",
    "    models_log = []\n",
    "    \n",
    "    for model in models:\n",
    "        logging.info(f\"Evaluating model: {model}\")\n",
    "        \n",
    "        correct_answers_counter = 0\n",
    "        errors_counter = 0\n",
    "        \n",
    "        tests_log = []\n",
    "        \n",
    "        model_log = {\n",
    "            \"model\": model,\n",
    "            \"valid_tests_number\": 0,\n",
    "            \"correct_answers_counter\": 0,\n",
    "            \"wrong_answers_counter\": 0,\n",
    "            \"errors_counter\": 0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"tests\": [],\n",
    "            \"model_evaluation_time\": 0.0\n",
    "        }\n",
    "        \n",
    "        model_start_time = time()\n",
    "        for i in range(repetitions):\n",
    "            logging.info(f\"Test {i+1}/{repetitions} for model {model}\")\n",
    "            test_log = {\"run\": i, \"short_answer\": None, \"confidence\": None, \"error_code\": None}\n",
    "                        \n",
    "            # send prompt to model and get response\n",
    "            response = send_prompt(model, prompt, csv_data)\n",
    "            \n",
    "            # check if there was a model error\n",
    "            if isinstance(response, Exception):\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.MODEL_ERROR\n",
    "                logging.error(f\"Model error for {model} on test {i+1}: {response}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # parse JSON response\n",
    "            try:\n",
    "                json_response = json.loads(response)\n",
    "                response_data = json_response.get('response', {})\n",
    "                \n",
    "                short_answer = response_data.get('short_answer', '').strip()\n",
    "                confidence = response_data.get('confidence', 0)\n",
    "                \n",
    "                # check missing short answer\n",
    "                if not short_answer:\n",
    "                    errors_counter += 1\n",
    "                    test_log[\"error_code\"] = LogErrorCode.MISSING_SHORT_ANSWER\n",
    "                    logging.error(f\"Missing short answer for {model} on test {i+1}\")\n",
    "                    tests_log.append(test_log)\n",
    "                    continue\n",
    "                \n",
    "                # correct answer check\n",
    "                if short_answer.lower() == domain[correct_answer_index].strip().lower():\n",
    "                    correct_answers_counter += 1\n",
    "                \n",
    "                # update log\n",
    "                test_log[\"short_answer\"] = short_answer\n",
    "                test_log[\"confidence\"] = confidence\n",
    "                    \n",
    "            except (TypeError, json.JSONDecodeError) as e:\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.JSON_PARSE_ERROR\n",
    "                logging.error(f\"JSON parse error for {model} on test {i+1}: {e}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # in the end of each test, append the test log\n",
    "            tests_log.append(test_log)\n",
    "            logging.info(f\"Test {i+1} for model {model} ended without errors!\")\n",
    "            \n",
    "        model_end_time = time()\n",
    "            \n",
    "        # update model log\n",
    "        valid_tests_number = repetitions - errors_counter\n",
    "        model_log[\"valid_tests_number\"] = valid_tests_number\n",
    "        model_log[\"correct_answers_counter\"] = correct_answers_counter\n",
    "        model_log[\"wrong_answers_counter\"] = valid_tests_number - correct_answers_counter\n",
    "        model_log[\"errors_counter\"] = errors_counter\n",
    "        model_log[\"accuracy\"] = (correct_answers_counter / valid_tests_number) * 100.0 if valid_tests_number > 0 else 0.0\n",
    "        model_log[\"tests\"] = tests_log\n",
    "        model_log[\"model_evaluation_time\"] = round(model_end_time - model_start_time, 1)\n",
    "        \n",
    "        # in the end of each model evaluation, append the model log\n",
    "        models_log.append(model_log)\n",
    "    \n",
    "    return models_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c79f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested models\n",
    "models = [\n",
    "    #\"x-ai/grok-4.1-fast:free\", # now is only for paying users\n",
    "    #\"meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    #\"nvidia/nemotron-nano-12b-v2-vl:free\",\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"mistralai/devstral-2512:free\",\n",
    "    #\"openrouter/bert-nebulon-alpha\",\n",
    "    #\"z-ai/glm-4.5-air:free\"\n",
    "    #\"amazon/nova-2-lite-v1:free\", # No JSON responses\n",
    "    #\"qwen/qwen3-coder:free\",\n",
    "    #\"google/gemma-3-27b-it:free\",\n",
    "    #\"openai/gpt-oss-20b:free\",\n",
    "    #\"meituan/longcat-flash-chat:free\",\n",
    "    #\"allenai/olmo-3-32b-think:free\",\n",
    "    #\"alibaba/tongyi-deepresearch-30b-a3b:free\",\n",
    "    #\"cognitivecomputations/dolphin-mistral-24b-venice-edition:free\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a964d",
   "metadata": {},
   "source": [
    "Vorrei creare un metodo che mi permetta di valutare COMPLETAMENTE una domanda, quindi restituire i risultati della domanda in questioni per ogni:\n",
    "- modello\n",
    "- dataset\n",
    "- formato del dataset\n",
    "\n",
    "Sarebbe da creare una funzione `evaluate(question, models, datasets, formats, n, [anon])`, che restituisca i risultati in uno o pi√π file JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcd04390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating model: kwaipilot/kat-coder-pro:free\n",
      "INFO:root:Test 1/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 2/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 3/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 4/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 5/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 6/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 6: Unterminated string starting at: line 1 column 914 (char 913)\n",
      "INFO:root:Test 7/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 8/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 9/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 10/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 11/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 12/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 13/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 14/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 14: Unterminated string starting at: line 6 column 21 (char 233)\n",
      "INFO:root:Test 15/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 16/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 17/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 18/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 19/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 20/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Evaluating model: tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:root:Test 1/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 2/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 3/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 4/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 5/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 6/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 7/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 8/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 9/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 10/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 11/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 12/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489550 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 13/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 14/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 15/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 16/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400161 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 17/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 18/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 19/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 20/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421460 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Evaluating model: mistralai/devstral-2512:free\n",
      "INFO:root:Test 1/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 2/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 3/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 4/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 5/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 6/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 7/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 8/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 9/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 10/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 11/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 12/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 13/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 14/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 15/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 16/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 17/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 18/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 19/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 20/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model mistralai/devstral-2512:free ended without errors!\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.today().strftime('%Y_%m_%d')\n",
    "start_hour = datetime.now().strftime('%H_%M_%S')\n",
    "start = time()\n",
    "\n",
    "repetitions = 20\n",
    "# simple switch for anonymized dataset evaluation\n",
    "anon = True\n",
    "if anon:\n",
    "    models_log = evaluate_models(models, prompt, anonymized_text_data, repetitions)\n",
    "else:\n",
    "    models_log = evaluate_models(models, prompt, text_data, repetitions)\n",
    "\n",
    "end = time()\n",
    "\n",
    "evaluation_time = end - start\n",
    "\n",
    "evaluation = {\n",
    "    \"question\": question,\n",
    "    \"tested_models\": models,\n",
    "    \"tested_dataset_name\": tested_dataset_name,\n",
    "    \"dataset_header_anonymization\": anon,\n",
    "    \"total_evaluation_time\": round(evaluation_time, 1),\n",
    "    \"models_log\": models_log,\n",
    "}\n",
    "\n",
    "dir_responses_path = f\"../responses/{start_date}/\"\n",
    "os.makedirs(os.path.dirname(dir_responses_path), exist_ok=True)\n",
    "with open(f\"{dir_responses_path}/{start_date}-{start_hour}_models_evaluation.json\", \"w\") as f:\n",
    "    json.dump(evaluation, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
