{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b35cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692546ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging setup\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a00c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    def __init__(self, id, text, answers_domain, correct_answer_index, context):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.answers_domain = answers_domain\n",
    "        self.correct_answer_index = correct_answer_index\n",
    "        self.context = context\n",
    "        \n",
    "    def is_correct(self, response):\n",
    "        \"\"\"Checks if the response matches the correct answer.\"\"\"\n",
    "        return response.strip().lower() == self.answers_domain[self.correct_answer_index].strip().lower()\n",
    "    \n",
    "    def get_prompt_text(self):\n",
    "        return f\"{self.id}: {self.text}\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.get_prompt_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4aed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    FORMAT_DESCRIPTIONS = {\n",
    "        'csv': (\n",
    "            \"You will receive a raw plaintext dataset in CSV format.\\nEach row represents a record, and each column represents an attribute of the data.\\nHeader is included in the first row.\"\n",
    "        ),\n",
    "\n",
    "        'horizontal_csv': (\n",
    "            \"You will receive a raw plaintext dataset in Horizontal CSV format.\\nHeader is included in the first column\\nEach column represents a record, and each row represents an attribute of the data.\"\n",
    "        ),\n",
    "\n",
    "        'json': (\n",
    "            \"You will receive a raw plaintext dataset in JSON format.\\nEach record is a JSON object with keys representing attributes.\"\n",
    "        ),\n",
    "\n",
    "        'markdown_kv': (\n",
    "            \"You will receive a raw plaintext dataset in Markdown Key-Value format.\\nEvery record is represented as a series of key-value pairs, with each pair on a new line and records separated by a line containing three dashes '---'.\"\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    def __init__(self, csv_path):\n",
    "        try:\n",
    "            self.df = pd.read_csv(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "            \n",
    "    # Methods to get text data in different formats  \n",
    "            \n",
    "    def get_csv_data(self):\n",
    "        return self.df.to_csv(index=False)\n",
    "\n",
    "    def get_horizontal_csv_data(self):\n",
    "        return self.df.transpose().to_csv(header=False, index=True)\n",
    "\n",
    "    def get_json_data(self):\n",
    "        return self.df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "    def get_md_kv_data(self):\n",
    "        output_lines = []\n",
    "        records = self.df.to_dict(orient='records')\n",
    "        \n",
    "        for record in records:\n",
    "            for key, value in record.items():\n",
    "                output_lines.append(f\"{key}: {value}\")\n",
    "            # Separator\n",
    "            output_lines.append(\"---\")\n",
    "                \n",
    "        return \"\\n\".join(output_lines)\n",
    "    \n",
    "    def get_formatted_data(self, format_type):\n",
    "        if format_type == 'csv':\n",
    "            return self.get_csv_data()\n",
    "        elif format_type == 'horizontal_csv':\n",
    "            return self.get_horizontal_csv_data()\n",
    "        elif format_type == 'json':\n",
    "            return self.get_json_data()\n",
    "        elif format_type == 'markdown_kv':\n",
    "            return self.get_md_kv_data()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format type: {format_type}\")\n",
    "    \n",
    "    # Method to get data format description for prompting\n",
    "    def get_format_description(self, format_type):\n",
    "        return self.FORMAT_DESCRIPTIONS.get(format_type, \"No description available for this format.\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a8371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionPrompt():\n",
    "    def __init__(self, question, dataset):\n",
    "        self.question = question\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def build_prompt(self, format_type='csv'):\n",
    "        base_prompt = \"You are an expert in Industrial Control Systems (ICS) and Operational Technology (OT), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\"\n",
    "        data_format = f\"# Data Format\\n{self.dataset.get_format_description(format_type)}\"\n",
    "        context_section = f\"# Context\\n{self.question.context}\"\n",
    "        task_section = f\"# Task\\nAnalyze the provided data to determine the physical architecture and answer precisely to this question:\\n{self.question.get_prompt_text()}\"\n",
    "\n",
    "        if len(self.question.context) != 0:    \n",
    "            prompt = f\"{base_prompt}\\n\\n{data_format}\\n\\n{task_section}\\n\\n{context_section}\\n\\n\"\n",
    "        else:\n",
    "            prompt = f\"{base_prompt}\\n\\n{data_format}\\n\\n{task_section}\\n\\n\"\n",
    "            \n",
    "        return prompt\n",
    "            \n",
    "    def build_data_prompt(self, format_type='csv'):\n",
    "        data = f\"# Data\\n{self.dataset.get_formatted_data(format_type)}\"\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71872764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogErrorCode():\n",
    "    MODEL_ERROR = 101\n",
    "    JSON_PARSE_ERROR = 201\n",
    "    MISSING_SHORT_ANSWER = 301\n",
    "    \n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        if code == self.MODEL_ERROR:\n",
    "            self.message = \"Model returned an error.\"\n",
    "        elif code == self.JSON_PARSE_ERROR:\n",
    "            self.message = \"Error parsing JSON response.\"\n",
    "        elif code == self.MISSING_SHORT_ANSWER:\n",
    "            self.message = \"Missing short answer in response.\"\n",
    "        else:\n",
    "            self.message = \"Unknown error code.\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[Error {self.code}]: {self.message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84cabf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OpenAI client\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"DENIS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2507815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(\"../datasets/swat/compressed_simplified-swat_plc-data-log_751-lines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404bc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "    'Energy & Power System',\n",
    "    'Oil, Gas & Chemicals System',\n",
    "    'Manufacturing System',\n",
    "    'Water & Wastewater System',\n",
    "    'Building Automation System',\n",
    "    'Not Identifiable'\n",
    "]\n",
    "\n",
    "q_1_1 = Question(\n",
    "    id=\"Q1.1\",\n",
    "    text=f\"Classify the physical Industrial Control System (ICS) into one of the following categories: {d}\",\n",
    "    answers_domain=d,\n",
    "    correct_answer_index=2,\n",
    "    context=\"\"\n",
    ")\n",
    "\n",
    "p_1_1 = QuestionPrompt(q_1_1, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc4b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.1 Possible ICS Type Identification\n",
    "domain = [\n",
    "    \"Power Generation Plant\",\n",
    "    \"Manufacturing Assembly Line\",\n",
    "    \"Oil and Gas Refinery\",\n",
    "    \"Water Purification Plant\",\n",
    "    \"Nuclear Power Plant\",\n",
    "    \"Not Identifiable\"\n",
    "]\n",
    "correct_answer_index = 3 # Water Purification Plant\n",
    "\n",
    "question = f\"Q1.1: Infer, based on data provided, what type of phisical Industrial Control System (ICS) between the following options: {domain}\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344f4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [str(i) for i in range(11)]\n",
    "\n",
    "q_2_1 = Question(\n",
    "    id=\"Q2.1\",\n",
    "    text=f\"Identify how many water tanks are involved during the operations of the ICS under consideration between the following options: {d}.\",\n",
    "    answers_domain=d,\n",
    "    correct_answer_index=3,\n",
    "    context=\"The ICS is catagorized as a Water & Wastewater System.\"\n",
    ")\n",
    "\n",
    "p_2_1 = QuestionPrompt(q_2_1, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb43eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1 Tanks Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q2.1: Only based on data provided, identify how many tanks are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83d7bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1 PLCs Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q3.1: Based on provided data and context, identify how many PLCs are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes. The operations involve three water tanks having varying capacities.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8274ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send prompt to model\n",
    "def send_prompt(model_name, question: Question, prompt: QuestionPrompt, format_type):\n",
    "    '''\n",
    "    Sends the constructed prompt to the specified model and retrieves the response.\n",
    "    '''\n",
    "    try:\n",
    "        c = CLIENT.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt.build_prompt(format_type)}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt.build_data_prompt(format_type)}]\n",
    "                },\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"response\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"response\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"short_answer\": {\n",
    "                                        \"enum\": question.answers_domain,\n",
    "                                    },\n",
    "                                    \"confidence\": {\n",
    "                                        \"type\": \"number\",\n",
    "                                        \"description\": \"Confidence level from 0 to 1, where 1 is highest\"\n",
    "                                    },\n",
    "                                    \"reasoning\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Reasoning behind the answer\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"short_answer\", \"confidence\", \"reasoning\"]\n",
    "                            },\n",
    "                            \"limitations\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"List of limitations or uncertainties in the analysis\"\n",
    "                            },\n",
    "                            \"internal_checks\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"columns_used\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of columns from the dataset that were used in the analysis\"\n",
    "                                    },\n",
    "                                    \"assumptions_detected\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of assumptions made during the analysis\"\n",
    "                                    },\n",
    "                                    \"warnings\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of warnings or potential issues identified during the analysis\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"columns_used\", \"assumptions_detected\", \"warnings\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"response\", \"limitations\", \"internal_checks\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw = c.choices[0].message.content\n",
    "        if not raw:\n",
    "            raise Exception(\"No content in response\")\n",
    "        return raw\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3697e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, prompt, csv_data, repetitions=10):\n",
    "    '''\n",
    "    Evalute accuracy of multiple models on the given prompt and data.\n",
    "    '''\n",
    "    models_log = []\n",
    "    \n",
    "    for model in models:\n",
    "        logging.info(f\"Evaluating model: {model}\")\n",
    "        \n",
    "        correct_answers_counter = 0\n",
    "        errors_counter = 0\n",
    "        \n",
    "        tests_log = []\n",
    "        \n",
    "        model_log = {\n",
    "            \"model\": model,\n",
    "            \"valid_tests_number\": 0,\n",
    "            \"correct_answers_counter\": 0,\n",
    "            \"wrong_answers_counter\": 0,\n",
    "            \"errors_counter\": 0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"tests\": [],\n",
    "            \"model_evaluation_time\": 0.0\n",
    "        }\n",
    "        \n",
    "        model_start_time = time()\n",
    "        for i in range(repetitions):\n",
    "            logging.info(f\"Test {i+1}/{repetitions} for model {model}\")\n",
    "            test_log = {\"run\": i, \"short_answer\": None, \"confidence\": None, \"error_code\": None}\n",
    "                        \n",
    "            # send prompt to model and get response\n",
    "            response = send_prompt(model, prompt, csv_data)\n",
    "            \n",
    "            # check if there was a model error\n",
    "            if isinstance(response, Exception):\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.MODEL_ERROR\n",
    "                logging.error(f\"Model error for {model} on test {i+1}: {response}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # parse JSON response\n",
    "            try:\n",
    "                json_response = json.loads(response)\n",
    "                response_data = json_response.get('response', {})\n",
    "                \n",
    "                short_answer = response_data.get('short_answer', '').strip()\n",
    "                confidence = response_data.get('confidence', 0)\n",
    "                \n",
    "                # check missing short answer\n",
    "                if not short_answer:\n",
    "                    errors_counter += 1\n",
    "                    test_log[\"error_code\"] = LogErrorCode.MISSING_SHORT_ANSWER\n",
    "                    logging.error(f\"Missing short answer for {model} on test {i+1}\")\n",
    "                    tests_log.append(test_log)\n",
    "                    continue\n",
    "                \n",
    "                # correct answer check\n",
    "                if short_answer.lower() == domain[correct_answer_index].strip().lower():\n",
    "                    correct_answers_counter += 1\n",
    "                \n",
    "                # update log\n",
    "                test_log[\"short_answer\"] = short_answer\n",
    "                test_log[\"confidence\"] = confidence\n",
    "                    \n",
    "            except (TypeError, json.JSONDecodeError) as e:\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.JSON_PARSE_ERROR\n",
    "                logging.error(f\"JSON parse error for {model} on test {i+1}: {e}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # in the end of each test, append the test log\n",
    "            tests_log.append(test_log)\n",
    "            logging.info(f\"Test {i+1} for model {model} ended without errors!\")\n",
    "            \n",
    "        model_end_time = time()\n",
    "            \n",
    "        # update model log\n",
    "        valid_tests_number = repetitions - errors_counter\n",
    "        model_log[\"valid_tests_number\"] = valid_tests_number\n",
    "        model_log[\"correct_answers_counter\"] = correct_answers_counter\n",
    "        model_log[\"wrong_answers_counter\"] = valid_tests_number - correct_answers_counter\n",
    "        model_log[\"errors_counter\"] = errors_counter\n",
    "        model_log[\"accuracy\"] = (correct_answers_counter / valid_tests_number) * 100.0 if valid_tests_number > 0 else 0.0\n",
    "        model_log[\"tests\"] = tests_log\n",
    "        model_log[\"model_evaluation_time\"] = round(model_end_time - model_start_time, 1)\n",
    "        \n",
    "        # in the end of each model evaluation, append the model log\n",
    "        models_log.append(model_log)\n",
    "    \n",
    "    return models_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c79f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested models\n",
    "models = [\n",
    "    #\"x-ai/grok-4.1-fast:free\", # now is only for paying users\n",
    "    #\"meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    #\"nvidia/nemotron-nano-12b-v2-vl:free\",\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"mistralai/devstral-2512:free\",\n",
    "    #\"openrouter/bert-nebulon-alpha\",\n",
    "    #\"z-ai/glm-4.5-air:free\"\n",
    "    #\"amazon/nova-2-lite-v1:free\", # No JSON responses\n",
    "    #\"qwen/qwen3-coder:free\",\n",
    "    #\"google/gemma-3-27b-it:free\",\n",
    "    #\"openai/gpt-oss-20b:free\",\n",
    "    #\"meituan/longcat-flash-chat:free\",\n",
    "    #\"allenai/olmo-3-32b-think:free\",\n",
    "    #\"alibaba/tongyi-deepresearch-30b-a3b:free\",\n",
    "    #\"cognitivecomputations/dolphin-mistral-24b-venice-edition:free\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5144da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested models\n",
    "models = [\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"mistralai/devstral-2512:free\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a964d",
   "metadata": {},
   "source": [
    "Vorrei creare un metodo che mi permetta di valutare COMPLETAMENTE una domanda, quindi restituire i risultati della domanda in questioni per ogni:\n",
    "- modello\n",
    "- dataset\n",
    "- formato del dataset\n",
    "\n",
    "Sarebbe da creare una funzione `evaluate(question, models, datasets, formats, n, [anon])`, che restituisca i risultati in uno o pi√π file JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcd04390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating model: kwaipilot/kat-coder-pro:free\n",
      "INFO:root:Test 1/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 2/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 3/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 4/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 5/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 6/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 6: Unterminated string starting at: line 1 column 914 (char 913)\n",
      "INFO:root:Test 7/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 8/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 9/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 10/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 11/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 12/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 13/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 14/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 14: Unterminated string starting at: line 6 column 21 (char 233)\n",
      "INFO:root:Test 15/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 16/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 17/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 18/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 19/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 20/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Evaluating model: tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:root:Test 1/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 2/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 3/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 4/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 5/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 6/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 7/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 8/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 9/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 10/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 11/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 12/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489550 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 13/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 14/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 15/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 16/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400161 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 17/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 18/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 19/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 20/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421460 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Evaluating model: mistralai/devstral-2512:free\n",
      "INFO:root:Test 1/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 2/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 3/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 4/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 5/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 6/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 7/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 8/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 9/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 10/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 11/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 12/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 13/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 14/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 15/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 16/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 17/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 18/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 19/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 20/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model mistralai/devstral-2512:free ended without errors!\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.today().strftime('%Y_%m_%d')\n",
    "start_hour = datetime.now().strftime('%H_%M_%S')\n",
    "start = time()\n",
    "\n",
    "repetitions = 20\n",
    "# simple switch for anonymized dataset evaluation\n",
    "anon = True\n",
    "if anon:\n",
    "    models_log = evaluate_models(models, prompt, anonymized_text_data, repetitions)\n",
    "else:\n",
    "    models_log = evaluate_models(models, prompt, text_data, repetitions)\n",
    "\n",
    "end = time()\n",
    "\n",
    "evaluation_time = end - start\n",
    "\n",
    "evaluation = {\n",
    "    \"question\": question,\n",
    "    \"tested_models\": models,\n",
    "    \"tested_dataset_name\": tested_dataset_name,\n",
    "    \"dataset_header_anonymization\": anon,\n",
    "    \"total_evaluation_time\": round(evaluation_time, 1),\n",
    "    \"models_log\": models_log,\n",
    "}\n",
    "\n",
    "dir_responses_path = f\"../responses/{start_date}/\"\n",
    "os.makedirs(os.path.dirname(dir_responses_path), exist_ok=True)\n",
    "with open(f\"{dir_responses_path}/{start_date}-{start_hour}_models_evaluation.json\", \"w\") as f:\n",
    "    json.dump(evaluation, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
