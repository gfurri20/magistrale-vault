{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b35cf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "692546ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging setup\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6a00c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    def __init__(self, id, text, answers_domain, correct_answer_index, context):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.answers_domain = answers_domain\n",
    "        self.correct_answer_index = correct_answer_index\n",
    "        self.context = context\n",
    "        \n",
    "    def is_correct(self, response):\n",
    "        \"\"\"Checks if the response matches the correct answer.\"\"\"\n",
    "        return response.strip().lower() == self.answers_domain[self.correct_answer_index].strip().lower()\n",
    "    \n",
    "    def get_prompt_text(self):\n",
    "        return f\"{self.id}: {self.text}\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.get_prompt_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa4aed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    FORMAT_DESCRIPTIONS = {\n",
    "        'csv': (\n",
    "            \"You will receive a raw plaintext dataset in CSV format.\\nEach row represents a record, and each column represents an attribute of the data.\\nHeader is included in the first row.\"\n",
    "        ),\n",
    "\n",
    "        'horizontal_csv': (\n",
    "            \"You will receive a raw plaintext dataset in Horizontal CSV format.\\nHeader is included in the first column\\nEach column represents a record, and each row represents an attribute of the data.\"\n",
    "        ),\n",
    "\n",
    "        'json': (\n",
    "            \"You will receive a raw plaintext dataset in JSON format.\\nEach record is a JSON object with keys representing attributes.\"\n",
    "        ),\n",
    "\n",
    "        'markdown_kv': (\n",
    "            \"You will receive a raw plaintext dataset in Markdown Key-Value format.\\nEvery record is represented as a series of key-value pairs, with each pair on a new line and records separated by a line containing three dashes '---'.\"\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    def __init__(self, csv_path):\n",
    "        try:\n",
    "            self.df = pd.read_csv(csv_path)\n",
    "            self.filepath = csv_path\n",
    "            self.filename = os.path.basename(csv_path)\n",
    "            # get dataset system name\n",
    "            self.system_name = csv_path.split(\"/\")[-2]\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "            \n",
    "    # Methods to get text data in different formats  \n",
    "            \n",
    "    def get_csv_data(self):\n",
    "        return self.df.to_csv(index=False)\n",
    "\n",
    "    def get_horizontal_csv_data(self):\n",
    "        return self.df.transpose().to_csv(header=False, index=True)\n",
    "\n",
    "    def get_json_data(self):\n",
    "        return self.df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "    def get_md_kv_data(self):\n",
    "        output_lines = []\n",
    "        records = self.df.to_dict(orient='records')\n",
    "        \n",
    "        for record in records:\n",
    "            for key, value in record.items():\n",
    "                output_lines.append(f\"{key}: {value}\")\n",
    "            # Separator\n",
    "            output_lines.append(\"---\")\n",
    "                \n",
    "        return \"\\n\".join(output_lines)\n",
    "    \n",
    "    def get_formatted_data(self, format_type):\n",
    "        if format_type == 'csv':\n",
    "            return self.get_csv_data()\n",
    "        elif format_type == 'horizontal_csv':\n",
    "            return self.get_horizontal_csv_data()\n",
    "        elif format_type == 'json':\n",
    "            return self.get_json_data()\n",
    "        elif format_type == 'markdown_kv':\n",
    "            return self.get_md_kv_data()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format type: {format_type}\")\n",
    "    \n",
    "    # Method to get data format description for prompting\n",
    "    def get_format_description(self, format_type):\n",
    "        return self.FORMAT_DESCRIPTIONS.get(format_type, \"No description available for this format.\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1a8371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionPrompt():\n",
    "    def __init__(self, question, dataset):\n",
    "        self.question = question\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def build_prompt(self, format_type='csv'):\n",
    "        base_prompt = \"You are an expert in Industrial Control Systems (ICS) and Operational Technology (OT), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\"\n",
    "        data_format = f\"# Data Format\\n{self.dataset.get_format_description(format_type)}\"\n",
    "        context_section = f\"# Context\\n{self.question.context}\"\n",
    "        task_section = f\"# Task\\nAnalyze the provided data to determine the physical architecture and answer to this question:\\n{self.question.get_prompt_text()}\"\n",
    "\n",
    "        if len(self.question.context) != 0:    \n",
    "            prompt = f\"{base_prompt}\\n\\n{data_format}\\n\\n{task_section}\\n\\n{context_section}\\n\\n\"\n",
    "        else:\n",
    "            prompt = f\"{base_prompt}\\n\\n{data_format}\\n\\n{task_section}\\n\\n\"\n",
    "            \n",
    "        return prompt\n",
    "            \n",
    "    def build_data_prompt(self, format_type='csv'):\n",
    "        data = f\"# Data\\n{self.dataset.get_formatted_data(format_type)}\"\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71872764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogErrorCode():\n",
    "    MODEL_ERROR = 101\n",
    "    JSON_PARSE_ERROR = 201\n",
    "    MISSING_SHORT_ANSWER = 301\n",
    "    \n",
    "    def __init__(self, code):\n",
    "        self.code = code\n",
    "        if code == self.MODEL_ERROR:\n",
    "            self.message = \"Model returned an error.\"\n",
    "        elif code == self.JSON_PARSE_ERROR:\n",
    "            self.message = \"Error parsing JSON response.\"\n",
    "        elif code == self.MISSING_SHORT_ANSWER:\n",
    "            self.message = \"Missing short answer in response.\"\n",
    "        else:\n",
    "            self.message = \"Unknown error code.\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"[Error {self.code}]: {self.message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84cabf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize OpenAI client\n",
    "CLIENT = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"DENIS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2507815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(\"../datasets/swat/compressed_simplified-swat_plc-data-log_750-lines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "404bc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "    'Energy & Power System',\n",
    "    'Oil, Gas & Chemicals System',\n",
    "    'Manufacturing System',\n",
    "    'Water & Wastewater System',\n",
    "    'Building Automation System',\n",
    "    'Not Identifiable'\n",
    "]\n",
    "\n",
    "q_1_1 = Question(\n",
    "    id=\"Q1-1\",\n",
    "    text=f\"Classify the physical Industrial Control System (ICS) into one of the following categories: {d}\",\n",
    "    answers_domain=d,\n",
    "    correct_answer_index=3,\n",
    "    context=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc4b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.1 Possible ICS Type Identification\n",
    "domain = [\n",
    "    \"Power Generation Plant\",\n",
    "    \"Manufacturing Assembly Line\",\n",
    "    \"Oil and Gas Refinery\",\n",
    "    \"Water Purification Plant\",\n",
    "    \"Nuclear Power Plant\",\n",
    "    \"Not Identifiable\"\n",
    "]\n",
    "correct_answer_index = 3 # Water Purification Plant\n",
    "\n",
    "question = f\"Q1.1: Infer, based on data provided, what type of phisical Industrial Control System (ICS) between the following options: {domain}\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344f4bde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m d = [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m11\u001b[39m)]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m q_2_1 = \u001b[43mQuestion\u001b[49m(\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mQ2-1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     text=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIdentify how many water tanks are involved during the operations of the ICS under consideration between the following options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     answers_domain=d,\n\u001b[32m      7\u001b[39m     correct_answer_index=\u001b[32m3\u001b[39m,\n\u001b[32m      8\u001b[39m     context=\u001b[33m\"\u001b[39m\u001b[33mThe ICS is catagorized as a Water & Wastewater System.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'Question' is not defined"
     ]
    }
   ],
   "source": [
    "d = [str(i) for i in range(11)]\n",
    "\n",
    "q_2_1 = Question(\n",
    "    id=\"Q2-1\",\n",
    "    text=f\"Identify how many water tanks are involved during the operations of the ICS under consideration between the following options: {d}.\",\n",
    "    answers_domain=d,\n",
    "    correct_answer_index=3,\n",
    "    context=\"The ICS is catagorized as a Water & Wastewater System.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb43eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1 Tanks Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q2.1: Only based on data provided, identify how many tanks are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83d7bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1 PLCs Number Identification\n",
    "domain = [str(i+1) for i in range(10)]\n",
    "correct_answer_index = 3 - 1 # Three Tanks in the ICS\n",
    "\n",
    "question = f\"Q3.1: Based on provided data and context, identify how many PLCs are involved during the operations of the ICS under consideration between the following options: {domain}\"\n",
    "context = \"The ICS is a simplified version of a Water Purification Plant. It produces filtered water through filtration and reverse osmosis processes. The operations involve three water tanks having varying capacities.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert in Industrial Control Systems (ICS), specialized in identifying system architecture and component relationships by analyzing time-series values of PLC registers.\n",
    "\n",
    "## Data Format\n",
    "You will receive a raw plaintext dataset in CSV form:\n",
    "- The first row contains column names (register labels).\n",
    "- All fields are comma-separated.\n",
    "- Each following row represents the register states at a specific timestamp.\n",
    "\n",
    "## Context\n",
    "{context}\n",
    "\n",
    "## Task\n",
    "Analyze the dataset and answer the following question:\n",
    "- {question}\n",
    "\n",
    "## Data (CSV)\"\"\".format(context=context,question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8274ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send prompt to model\n",
    "def send_prompt(model_name, question: Question, prompt: QuestionPrompt, format_type):\n",
    "    '''\n",
    "    Sends the constructed prompt to the specified model and retrieves the response.\n",
    "    '''\n",
    "    try:\n",
    "        c = CLIENT.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt.build_prompt(format_type)}]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": prompt.build_data_prompt(format_type)}]\n",
    "                },\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"response\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"response\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"short_answer\": {\n",
    "                                        \"enum\": question.answers_domain,\n",
    "                                    },\n",
    "                                    \"confidence\": {\n",
    "                                        \"type\": \"number\",\n",
    "                                        \"description\": \"Confidence level from 0 to 1, where 1 is highest\"\n",
    "                                    },\n",
    "                                    \"reasoning\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Reasoning behind the answer\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"short_answer\", \"confidence\", \"reasoning\"]\n",
    "                            },\n",
    "                            \"limitations\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"description\": \"List of limitations or uncertainties in the analysis\"\n",
    "                            },\n",
    "                            \"internal_checks\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"columns_used\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of columns from the dataset that were used in the analysis\"\n",
    "                                    },\n",
    "                                    \"assumptions_detected\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of assumptions made during the analysis\"\n",
    "                                    },\n",
    "                                    \"warnings\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"description\": \"List of warnings or potential issues identified during the analysis\"\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"columns_used\", \"assumptions_detected\", \"warnings\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"response\", \"limitations\", \"internal_checks\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw = c.choices[0].message.content\n",
    "        if not raw:\n",
    "            raise Exception(\"No content in response\")\n",
    "        return raw\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3697e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, prompt, csv_data, repetitions=10):\n",
    "    '''\n",
    "    Evalute accuracy of multiple models on the given prompt and data.\n",
    "    '''\n",
    "    models_log = []\n",
    "    \n",
    "    for model in models:\n",
    "        logging.info(f\"Evaluating model: {model}\")\n",
    "        \n",
    "        correct_answers_counter = 0\n",
    "        errors_counter = 0\n",
    "        \n",
    "        tests_log = []\n",
    "        \n",
    "        model_log = {\n",
    "            \"model\": model,\n",
    "            \"valid_tests_number\": 0,\n",
    "            \"correct_answers_counter\": 0,\n",
    "            \"wrong_answers_counter\": 0,\n",
    "            \"errors_counter\": 0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"tests\": [],\n",
    "            \"model_evaluation_time\": 0.0\n",
    "        }\n",
    "        \n",
    "        model_start_time = time()\n",
    "        for i in range(repetitions):\n",
    "            logging.info(f\"Test {i+1}/{repetitions} for model {model}\")\n",
    "            test_log = {\"run\": i, \"short_answer\": None, \"confidence\": None, \"error_code\": None}\n",
    "                        \n",
    "            # send prompt to model and get response\n",
    "            response = send_prompt(model, prompt, csv_data)\n",
    "            \n",
    "            # check if there was a model error\n",
    "            if isinstance(response, Exception):\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.MODEL_ERROR\n",
    "                logging.error(f\"Model error for {model} on test {i+1}: {response}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # parse JSON response\n",
    "            try:\n",
    "                json_response = json.loads(response)\n",
    "                response_data = json_response.get('response', {})\n",
    "                \n",
    "                short_answer = response_data.get('short_answer', '').strip()\n",
    "                confidence = response_data.get('confidence', 0)\n",
    "                \n",
    "                # check missing short answer\n",
    "                if not short_answer:\n",
    "                    errors_counter += 1\n",
    "                    test_log[\"error_code\"] = LogErrorCode.MISSING_SHORT_ANSWER\n",
    "                    logging.error(f\"Missing short answer for {model} on test {i+1}\")\n",
    "                    tests_log.append(test_log)\n",
    "                    continue\n",
    "                \n",
    "                # correct answer check\n",
    "                if short_answer.lower() == domain[correct_answer_index].strip().lower():\n",
    "                    correct_answers_counter += 1\n",
    "                \n",
    "                # update log\n",
    "                test_log[\"short_answer\"] = short_answer\n",
    "                test_log[\"confidence\"] = confidence\n",
    "                    \n",
    "            except (TypeError, json.JSONDecodeError) as e:\n",
    "                errors_counter += 1\n",
    "                test_log[\"error_code\"] = LogErrorCode.JSON_PARSE_ERROR\n",
    "                logging.error(f\"JSON parse error for {model} on test {i+1}: {e}\")\n",
    "                tests_log.append(test_log)\n",
    "                continue\n",
    "            \n",
    "            # in the end of each test, append the test log\n",
    "            tests_log.append(test_log)\n",
    "            logging.info(f\"Test {i+1} for model {model} ended without errors!\")\n",
    "            \n",
    "        model_end_time = time()\n",
    "            \n",
    "        # update model log\n",
    "        valid_tests_number = repetitions - errors_counter\n",
    "        model_log[\"valid_tests_number\"] = valid_tests_number\n",
    "        model_log[\"correct_answers_counter\"] = correct_answers_counter\n",
    "        model_log[\"wrong_answers_counter\"] = valid_tests_number - correct_answers_counter\n",
    "        model_log[\"errors_counter\"] = errors_counter\n",
    "        model_log[\"accuracy\"] = (correct_answers_counter / valid_tests_number) * 100.0 if valid_tests_number > 0 else 0.0\n",
    "        model_log[\"tests\"] = tests_log\n",
    "        model_log[\"model_evaluation_time\"] = round(model_end_time - model_start_time, 1)\n",
    "        \n",
    "        # in the end of each model evaluation, append the model log\n",
    "        models_log.append(model_log)\n",
    "    \n",
    "    return models_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which creates the evaluation log file\n",
    "def create_evaluation_log_file(json_log, question, dataset, dataset_format, model):\n",
    "    sanitized_model_name = model.split(\"/\")[1].replace(\":\", \"-\")\n",
    "    path = f\"../responses/{datetime.today().strftime('%Y_%m_%d')}/{dataset.system_name}/{sanitized_model_name}/{dataset_format}/\"\n",
    "    filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{question.id}.json\"\n",
    "    \n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(path, filename), 'w') as f:\n",
    "        json.dump(json_log, f, indent=4)\n",
    "\n",
    "    logging.info(f\"JSON log file created: {os.path.join(path, filename)}\")\n",
    "    \n",
    "\n",
    "def evaluate_question(question: Question, dataset: Dataset, dataset_format, model, iterations=10):\n",
    "    '''\n",
    "    Evaluate a question on a specific configuration of based on dataset, dataset format and LLM model.\n",
    "    Produce a file json log with results.\n",
    "    '''\n",
    "    # initialize json log structure\n",
    "    json_log = {\n",
    "        \"experiment_id\": f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "        \"config\": {\n",
    "            \"model\": model,\n",
    "            \"dataset_format\": dataset_format,\n",
    "            \"iterations\": iterations,\n",
    "            \"question\": question.get_prompt_text()\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"filepath\": dataset.filepath,\n",
    "            \"system_name\": dataset.system_name,\n",
    "            \"is_anon\": True if \"anonymized\" in dataset.filename else False\n",
    "        },\n",
    "        \"runs\": [],\n",
    "        \"aggregated_stats\": {\n",
    "            \"correct_n\": 0,\n",
    "            \"incorrect_n\": 0,\n",
    "            \"error_n\": 0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"reliability\": 0.0,\n",
    "            \"precision\": 0.0,\n",
    "            \"evaluation_time\": 0.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    correct_n = 0\n",
    "    error_n = 0\n",
    "    runs_log = []\n",
    "    \n",
    "    start_time = time()\n",
    "    for i in range(iterations):\n",
    "        logging.info(f\"Starting run {i+1}/{iterations} for question {question.id}, model {model} and dataset {dataset.system_name}\")\n",
    "        run_log = {\"run\": i, \"short_answer\": None, \"confidence\": None, \"reasoning\": None}\n",
    "        error_log = {\"code\": None, \"msg\": None}\n",
    "        \n",
    "        # send prompt to model and get response\n",
    "        response = send_prompt(model, question, QuestionPrompt(question, dataset), dataset_format)\n",
    "        \n",
    "        # check if there was a model error\n",
    "        if isinstance(response, Exception):\n",
    "            error_n += 1\n",
    "            error_log[\"code\"] = LogErrorCode.MODEL_ERROR\n",
    "            error_log[\"msg\"] = LogErrorCode(LogErrorCode.MODEL_ERROR).message\n",
    "            logging.error(f\"Model error for {model} on test {i+1}: {response}\")\n",
    "            # add error log to run log\n",
    "            run_log.update(error_log)\n",
    "            continue\n",
    "        \n",
    "        # parse JSON response\n",
    "        try:\n",
    "            # load json from the response\n",
    "            json_response = json.loads(response)\n",
    "            response_data = json_response.get('response', {})\n",
    "            \n",
    "            # get short answer and confidence\n",
    "            short_answer = response_data.get('short_answer', '').strip()\n",
    "            confidence = response_data.get('confidence', 0)\n",
    "            reasoning = response_data.get('reasoning', '').strip()\n",
    "            \n",
    "            # check missing short answer\n",
    "            if not short_answer:\n",
    "                error_n += 1\n",
    "                error_log[\"error_code\"] = LogErrorCode.MISSING_SHORT_ANSWER\n",
    "                error_log[\"msg\"] = LogErrorCode(LogErrorCode.MISSING_SHORT_ANSWER).message\n",
    "                logging.error(f\"Missing short answer for {model} on test {i+1}\")\n",
    "                # add error log to run log\n",
    "                run_log.update(error_log)\n",
    "                continue\n",
    "            \n",
    "            # correct answer check\n",
    "            if question.is_correct(short_answer):\n",
    "                correct_n += 1\n",
    "            \n",
    "            # update log\n",
    "            run_log[\"short_answer\"] = short_answer\n",
    "            run_log[\"confidence\"] = confidence\n",
    "            run_log[\"reasoning\"] = reasoning\n",
    "            \n",
    "        # handle JSON parse errors\n",
    "        except (TypeError, json.JSONDecodeError) as e:\n",
    "            error_n += 1\n",
    "            error_log[\"error_code\"] = LogErrorCode.JSON_PARSE_ERROR\n",
    "            error_log[\"msg\"] = LogErrorCode(LogErrorCode.JSON_PARSE_ERROR).message\n",
    "            logging.error(f\"JSON parse error for {model} on test {i+1}: {e}\")\n",
    "            # add error log to run log\n",
    "            run_log.update(error_log)\n",
    "            continue\n",
    "        \n",
    "        # in the end of each test, append the test log\n",
    "        runs_log.append(run_log)\n",
    "        logging.info(f\"Run {i+1} for question {question.id} and model {model} ended without errors!\")\n",
    "        \n",
    "    \n",
    "    end_time = time()\n",
    "    evaluation_time = round(end_time - start_time, 1)\n",
    "    # calculate the number of valid iterations for avoid division by zero\n",
    "    valid_iterations = iterations - error_n\n",
    "    \n",
    "    # add runs to json log\n",
    "    json_log[\"runs\"] = runs_log\n",
    "    \n",
    "    # add aggregated stats to json log\n",
    "    json_log[\"aggregated_stats\"][\"correct_n\"] = correct_n\n",
    "    json_log[\"aggregated_stats\"][\"incorrect_n\"] = iterations - correct_n - error_n\n",
    "    json_log[\"aggregated_stats\"][\"error_n\"] = error_n\n",
    "    json_log[\"aggregated_stats\"][\"accuracy\"] = round(correct_n / iterations, 2) * 100.0\n",
    "    json_log[\"aggregated_stats\"][\"reliability\"] = round((valid_iterations) / iterations, 2) * 100.0\n",
    "    json_log[\"aggregated_stats\"][\"precision\"] = round(correct_n / valid_iterations, 2) * 100.0 if valid_iterations > 0 else 0.0\n",
    "    json_log[\"aggregated_stats\"][\"evaluation_time\"] = round(evaluation_time, 3)\n",
    "    \n",
    "    # create evaluation log file\n",
    "    create_evaluation_log_file(json_log, question, dataset, dataset_format, model)\n",
    "    \n",
    "    return json_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8112fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting run 1/5 for question Q2.1, model mistralai/devstral-2512:free and dataset swat\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Run 1 for question Q2.1 and model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Starting run 2/5 for question Q2.1, model mistralai/devstral-2512:free and dataset swat\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Run 2 for question Q2.1 and model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Starting run 3/5 for question Q2.1, model mistralai/devstral-2512:free and dataset swat\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Run 3 for question Q2.1 and model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Starting run 4/5 for question Q2.1, model mistralai/devstral-2512:free and dataset swat\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Run 4 for question Q2.1 and model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Starting run 5/5 for question Q2.1, model mistralai/devstral-2512:free and dataset swat\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Run 5 for question Q2.1 and model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:JSON log file created: ../responses/2026_01_21/swat/devstral-2512:free/horizontal_csv/20260121_231156_Q2.1.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 'exp_20260121_230935',\n",
       " 'config': {'model': 'mistralai/devstral-2512:free',\n",
       "  'dataset_format': 'horizontal_csv',\n",
       "  'iterations': 5,\n",
       "  'question': \"Q2.1: Identify how many water tanks are involved during the operations of the ICS under consideration between the following options: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'].\"},\n",
       " 'dataset': {'filepath': '../datasets/swat/compressed_simplified-swat_plc-data-log_750-lines.csv',\n",
       "  'system_name': 'swat',\n",
       "  'is_anon': False},\n",
       " 'runs': [{'run': 0,\n",
       "   'short_answer': '2',\n",
       "   'confidence': 0.85,\n",
       "   'reasoning': 'The analysis of the provided data suggests the presence of two water tanks in the ICS. This conclusion is drawn from the observation of two distinct patterns in the PLC registers, particularly in PLC1_IR0 and PLC2_IR0, which exhibit cyclic behavior indicative of tank filling and draining processes. The presence of two separate control signals (PLC1_C0 and PLC2_C0) further supports the existence of two independent tanks.'},\n",
       "  {'run': 1,\n",
       "   'short_answer': '2',\n",
       "   'confidence': 0.85,\n",
       "   'reasoning': 'The analysis of the provided data suggests the presence of two water tanks in the ICS. This conclusion is drawn from the observation of two distinct patterns in the PLC registers, particularly in PLC1_IR0 and PLC2_IR0, which exhibit cyclic behavior indicative of tank filling and draining processes. The coherence between the control signals (PLC1_C0, PLC1_C1, PLC2_C0, PLC3_C0, PLC3_C1) and the input registers further supports this interpretation. The data shows two separate cycles of operation, likely corresponding to two tanks.'},\n",
       "  {'run': 2,\n",
       "   'short_answer': '2',\n",
       "   'confidence': 0.85,\n",
       "   'reasoning': 'The analysis of the provided data suggests the presence of two water tanks in the ICS. This conclusion is drawn from the observation of two distinct patterns in the time-series values of PLC registers, particularly in PLC1_IR0 and PLC2_IR0. These patterns indicate separate operational cycles and levels that are characteristic of two independent water tanks. The confidence level is 0.85 due to the consistency and separation of these patterns.'},\n",
       "  {'run': 3,\n",
       "   'short_answer': '2',\n",
       "   'confidence': 0.9,\n",
       "   'reasoning': 'The analysis of the provided data suggests the presence of two water tanks in the ICS. This conclusion is drawn from the observation of two distinct patterns in the time-series values of PLC registers, particularly in PLC1_IR0 and PLC2_IR0. These patterns indicate the operation of two separate tanks, as the values fluctuate in a manner consistent with the filling and draining cycles of two independent systems. Additionally, the coherence between the control signals (PLC1_C0, PLC1_C1, PLC2_C0, PLC3_C0, PLC3_C1) and the input registers supports the inference of two tanks being managed by the system.'},\n",
       "  {'run': 4,\n",
       "   'short_answer': '2',\n",
       "   'confidence': 0.85,\n",
       "   'reasoning': 'The analysis of the provided data suggests the presence of two water tanks in the ICS. This conclusion is drawn from the observation of two distinct patterns in the time-series data of PLC registers, particularly in PLC1_IR0 and PLC2_IR0. These patterns indicate the operation of two separate tanks, as evidenced by the periodic fluctuations and correlations in their values. Additionally, the control signals (PLC1_C0, PLC1_C1, PLC2_C0, PLC3_C0, PLC3_C1) show coordinated behavior that aligns with the operation of two tanks, further supporting this conclusion.'}],\n",
       " 'aggregated_stats': {'correct_n': 0,\n",
       "  'incorrect_n': 5,\n",
       "  'error_n': 0,\n",
       "  'accuracy': 0.0,\n",
       "  'reliability': 100.0,\n",
       "  'precision': 0.0,\n",
       "  'evaluation_time': 141.0}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_question(q_2_1, ds, 'horizontal_csv', 'mistralai/devstral-2512:free', iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c79f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested models\n",
    "models = [\n",
    "    #\"x-ai/grok-4.1-fast:free\", # now is only for paying users\n",
    "    #\"meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    #\"nvidia/nemotron-nano-12b-v2-vl:free\",\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"mistralai/devstral-2512:free\",\n",
    "    #\"openrouter/bert-nebulon-alpha\",\n",
    "    #\"z-ai/glm-4.5-air:free\"\n",
    "    #\"amazon/nova-2-lite-v1:free\", # No JSON responses\n",
    "    #\"qwen/qwen3-coder:free\",\n",
    "    #\"google/gemma-3-27b-it:free\",\n",
    "    #\"openai/gpt-oss-20b:free\",\n",
    "    #\"meituan/longcat-flash-chat:free\",\n",
    "    #\"allenai/olmo-3-32b-think:free\",\n",
    "    #\"alibaba/tongyi-deepresearch-30b-a3b:free\",\n",
    "    #\"cognitivecomputations/dolphin-mistral-24b-venice-edition:free\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c5144da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested models\n",
    "models = [\n",
    "    \"kwaipilot/kat-coder-pro:free\",\n",
    "    \"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    \"mistralai/devstral-2512:free\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a964d",
   "metadata": {},
   "source": [
    "Vorrei creare un metodo che mi permetta di valutare COMPLETAMENTE una domanda, quindi restituire i risultati della domanda in questioni per ogni:\n",
    "- modello\n",
    "- dataset\n",
    "- formato del dataset\n",
    "\n",
    "Sarebbe da creare una funzione `evaluate(question, models, datasets, formats, n, [anon])`, che restituisca i risultati in uno o pi√π file JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcd04390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating model: kwaipilot/kat-coder-pro:free\n",
      "INFO:root:Test 1/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 2/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 3/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 4/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 5/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 6/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 6: Unterminated string starting at: line 1 column 914 (char 913)\n",
      "INFO:root:Test 7/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 8/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 9/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 10/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 11/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 12/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 13/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 14/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "ERROR:root:JSON parse error for kwaipilot/kat-coder-pro:free on test 14: Unterminated string starting at: line 6 column 21 (char 233)\n",
      "INFO:root:Test 15/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 16/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 17/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 18/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 19/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Test 20/20 for model kwaipilot/kat-coder-pro:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model kwaipilot/kat-coder-pro:free ended without errors!\n",
      "INFO:root:Evaluating model: tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:root:Test 1/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 2/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 3/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 4/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 5/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 6/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 7/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 8/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 9/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 10/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 11/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 12/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.489550 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 13/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 14/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 15/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 16/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.400161 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 17/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 18/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 19/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Test 20/20 for model tngtech/deepseek-r1t2-chimera:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.421460 seconds\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model tngtech/deepseek-r1t2-chimera:free ended without errors!\n",
      "INFO:root:Evaluating model: mistralai/devstral-2512:free\n",
      "INFO:root:Test 1/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 1 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 2/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 2 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 3/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 3 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 4/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 4 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 5/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 5 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 6/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 6 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 7/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 7 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 8/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 8 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 9/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 9 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 10/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 10 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 11/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 11 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 12/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 12 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 13/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 13 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 14/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 14 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 15/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 15 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 16/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 16 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 17/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 17 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 18/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 18 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 19/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 19 for model mistralai/devstral-2512:free ended without errors!\n",
      "INFO:root:Test 20/20 for model mistralai/devstral-2512:free\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Test 20 for model mistralai/devstral-2512:free ended without errors!\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.today().strftime('%Y_%m_%d')\n",
    "start_hour = datetime.now().strftime('%H_%M_%S')\n",
    "start = time()\n",
    "\n",
    "repetitions = 20\n",
    "# simple switch for anonymized dataset evaluation\n",
    "anon = True\n",
    "if anon:\n",
    "    models_log = evaluate_models(models, prompt, anonymized_text_data, repetitions)\n",
    "else:\n",
    "    models_log = evaluate_models(models, prompt, text_data, repetitions)\n",
    "\n",
    "end = time()\n",
    "\n",
    "evaluation_time = end - start\n",
    "\n",
    "evaluation = {\n",
    "    \"question\": question,\n",
    "    \"tested_models\": models,\n",
    "    \"tested_dataset_name\": tested_dataset_name,\n",
    "    \"dataset_header_anonymization\": anon,\n",
    "    \"total_evaluation_time\": round(evaluation_time, 1),\n",
    "    \"models_log\": models_log,\n",
    "}\n",
    "\n",
    "dir_responses_path = f\"../responses/{start_date}/\"\n",
    "os.makedirs(os.path.dirname(dir_responses_path), exist_ok=True)\n",
    "with open(f\"{dir_responses_path}/{start_date}-{start_hour}_models_evaluation.json\", \"w\") as f:\n",
    "    json.dump(evaluation, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
